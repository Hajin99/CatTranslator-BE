import matplotlib
from flask import Flask, request, send_file, jsonify
import librosa
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import numpy as np
import io
import os
import soundfile as sf


app = Flask(__name__)

# ì´ë¯¸ì§€ í˜•íƒœë¡œ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
@app.route('/analyze', methods=['POST'])
def analyze():
    # 1. íŒŒì¼ ì €ì¥
    data = request.get_data()
    with open("temp.wav", "wb") as f:
        f.write(data)
    print("temp.wav í¬ê¸°:", os.path.getsize("temp.wav"))

    # ë””ë²„ê¹…ìš©
    sf_data, sf_sr = sf.read("temp.wav")
    print("sf_data:", sf_data.shape, sf_sr)
    print("ìƒ˜í”Œ ì¼ë¶€:", sf_data[:10])

    # 2. ì£¼íŒŒìˆ˜ ë¶„ì„
    y, sr = librosa.load("temp.wav", sr=None)
    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
    print("y sample:", y[:10])

    # 3. ê·¸ë˜í”„ ìƒì„±
    fig, ax = plt.subplots(figsize=(15, 6))
    # ê°œì„ : 0ì´ ì•„ë‹Œ ê°’ë§Œ ì¶”ì¶œí•´ì„œ ìœ¤ê³½ ìƒì„±
    pitch_track = []
    for t in range(pitches.shape[1]):
        index = magnitudes[:, t].argmax()
        pitch = pitches[index, t]
        pitch_track.append(pitch)
    pitch_track = np.array(pitch_track)

    # ì •ê·œí™”: yì¶•ì„ 0 ~ 12 ë²”ìœ„ë¡œ ë‹¨ìˆœí™”
    pitch_track = pitch_track / np.max(pitch_track) * 10  # ë˜ëŠ” 12
    #ax.plot(np.max(pitches, axis=0))  # í”„ë ˆì„ë³„ ìµœëŒ€ í”¼ì¹˜ ì‹œê°í™”
    # ax.plot(np.mean(pitches, axis=0))  # ê°„ë‹¨íˆ í‰ê·  í”¼ì¹˜ ì‹œê°í™”
    ax.plot(pitch_track, color='black', linewidth=2)
    ax.set_yticks(np.arange(0, 13, 2))
    ax.set_xticks([])
    ax.grid(True, linestyle=':', linewidth=0.5)
    for side in ['top', 'right']:
        ax.spines[side].set_visible(False)
    for side in ['left', 'bottom']:
        ax.spines[side].set_linewidth(1)
    ax.set_title("Pitch Over Time")
    ax.set_xlabel("Frame")
    ax.set_ylabel("Frequency (Hz)")

    # 4. PNG ë³€í™˜ í›„ ì‘ë‹µ
    img_io = io.BytesIO()
    plt.savefig(img_io, format='png')
    img_io.seek(0)
    plt.close(fig)

    return send_file(img_io, mimetype='image/png')


# json í˜•íƒœë¡œ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
@app.route('/emotion', methods=['POST'])
def emotion():
    print("Flask /emotion ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨")
    print(f"Request files: {request.files}") # ğŸ’¡ ì¶”ê°€: Flaskê°€ ë°›ì€ íŒŒì¼ íŒŒíŠ¸
    # 1. íŒŒì¼ ì €ì¥
    data = request.get_data()
    with open("temp.wav", "wb") as f:
        f.write(data)

    # 2. ì£¼íŒŒìˆ˜ ë¶„ì„
    y, sr = librosa.load("temp.wav", sr=None)
    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)

    # 3. í”¼ì¹˜ ê°’ ì¶”ì¶œ (ê°„ë‹¨í•œ ë¶„ì„ìš©)
    pitch_track = []
    for t in range(pitches.shape[1]):
        index = magnitudes[:, t].argmax()
        pitch = pitches[index, t]
        pitch_track.append(pitch)
    pitch_track = [float(p) for p in pitch_track if p > 0.0]

    # 4. JSON í˜•íƒœë¡œ ì‘ë‹µ
    result = {
        "pitch_mean": np.mean(pitch_track),
        "pitch_max": np.max(pitch_track),
        "pitch_min": np.min(pitch_track),
        "sample_count": len(pitch_track)
    }

    return jsonify(result)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5050)